<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/.dockerignore">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/.dockerignore" />
              <option name="originalContent" value="**/.dockerignore&#10;**/.git&#10;**/.gitignore&#10;**/.vs&#10;**/.vscode&#10;**/.idea&#10;**/*.*proj.user&#10;**/*.dbmdl&#10;**/*.jfm&#10;**/bin&#10;**/obj&#10;**/charts&#10;**/docker-compose*&#10;**/compose*&#10;**/.toolstarget&#10;**/.classpath&#10;**/.project&#10;**/.settings&#10;**/Dockerfile*&#10;**/*.log&#10;**/*.md&#10;**/.DS_Store&#10;LICENSE&#10;README.md&#10;**/node_modules&#10;**/.env&#10;&#10;" />
              <option name="updatedContent" value="**/.dockerignore&#10;**/.git&#10;**/.gitignore&#10;**/.vs&#10;**/.vscode&#10;**/.idea&#10;**/*.*proj.user&#10;**/*.dbmdl&#10;**/*.jfm&#10;**/bin&#10;**/obj&#10;**/charts&#10;**/docker-compose*&#10;**/compose*&#10;**/.toolstarget&#10;**/.classpath&#10;**/.project&#10;**/.settings&#10;**/Dockerfile*&#10;**/*.log&#10;**/*.md&#10;**/.DS_Store&#10;LICENSE&#10;README.md&#10;**/node_modules&#10;**/.env&#10;**/docker-init&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/.env.example">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/.env.example" />
              <option name="originalContent" value="# SQL Server Configuration&#10;SA_PASSWORD=YourStrong@Password123&#10;&#10;# Elasticsearch Configuration&#10;ELASTICSEARCH_URI=http://elasticsearch:9200&#10;&#10;# API Configuration&#10;API_PORT=5000&#10;&#10;# Environment&#10;ASPNETCORE_ENVIRONMENT=Development&#10;&#10;" />
              <option name="updatedContent" value="# SQL Server Configuration&#10;# SA account (for initial setup only)&#10;SA_PASSWORD=YourStrong@Password123&#10;&#10;# Admin user credentials (used by API and Jobs)&#10;DB_USER=admin&#10;DB_PASSWORD=Password1234&#10;&#10;# Elasticsearch Configuration&#10;ELASTICSEARCH_URI=http://elasticsearch:9200&#10;&#10;# API Configuration&#10;API_PORT=5000&#10;&#10;# Environment&#10;ASPNETCORE_ENVIRONMENT=Development&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/ADMIN-USER-SETUP.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/ADMIN-USER-SETUP.md" />
              <option name="updatedContent" value="# ✅ SQL Server Admin User Setup - Complete!&#10;&#10;##  რა შეიცვალა&#10;&#10;### Before (sa account):&#10;```yaml&#10;User Id=sa&#10;Password=YourStrong@Password123&#10;```&#10;&#10;### After (admin account):&#10;```yaml&#10;User Id=admin&#10;Password=Password1234&#10;```&#10;&#10;---&#10;&#10;##  Summary&#10;&#10;| Component | Username | Password |&#10;|-----------|----------|----------|&#10;| **SA Account** | `sa` | `YourStrong@Password123` |&#10;| **Application User** | `admin` | `Password1234` |&#10;| **API Connection** | `admin` | `Password1234` |&#10;| **Jobs Connection** | `admin` | `Password1234` |&#10;| **Hangfire Connection** | `admin` | `Password1234` |&#10;&#10;---&#10;&#10;##  შექმნილი ფაილები&#10;&#10;1. **`docker-init/entrypoint.sh`**  &#10;   Custom entrypoint რომელიც ასრულებს SQL init scripts&#10;&#10;2. **`docker-init/01-create-admin-user.sql`**  &#10;   SQL script რომელიც ქმნის `admin` user-ს&#10;&#10;3. **`docker-init/README.md`**  &#10;   დოკუმენტაცია initialization process-ის შესახებ&#10;&#10;---&#10;&#10;##  განახლებული ფაილები&#10;&#10;### ✅ `docker-compose.yml`&#10;- ✅ SA_PASSWORD: `YourStrong@Password123` (setup-სთვის)&#10;- ✅ Healthcheck: იყენებს `admin` user-ს&#10;- ✅ API: უკავშირდება `admin`-ით&#10;- ✅ Jobs: უკავშირდება `admin`-ით&#10;- ✅ Volume mount: `./docker-init:/docker-entrypoint-initdb.d`&#10;- ✅ Custom entrypoint: `/docker-entrypoint-initdb.d/entrypoint.sh`&#10;&#10;### ✅ `.env.example`&#10;```env&#10;SA_PASSWORD=YourStrong@Password123  # Initial setup&#10;DB_USER=admin&#10;DB_PASSWORD=Password1234&#10;```&#10;&#10;### ✅ `.dockerignore`&#10;- ✅ დამატებულია `**/docker-init` (რადგან volume-ში mount-დება)&#10;&#10;---&#10;&#10;##  როგორ გამოვიყენოთ&#10;&#10;### 1️⃣ Clean Start (რეკომენდებული):&#10;```bash&#10;# Stop and remove old volumes&#10;docker-compose down -v&#10;&#10;# Start with fresh setup&#10;docker-compose up -d&#10;&#10;# Watch logs&#10;docker-compose logs -f sqlserver&#10;```&#10;&#10;### 2️⃣ რას ნახავთ logs-ში:&#10;```&#10;Starting SQL Server...&#10;Waiting for SQL Server to start...&#10;Running SQL initialization scripts...&#10;Executing /docker-entrypoint-initdb.d/01-create-admin-user.sql...&#10;Login [admin] created successfully&#10;Database [ElasticsearchDemo] created successfully&#10;User [admin] created successfully&#10;Setup completed: admin user with Password1234&#10;```&#10;&#10;### 3️⃣ შემოწმება:&#10;```bash&#10;# Test admin login&#10;docker exec -it sqlserver /opt/mssql-tools/bin/sqlcmd -S localhost -U admin -P Password1234&#10;&#10;1&gt; SELECT SYSTEM_USER;&#10;2&gt; GO&#10;```&#10;&#10;---&#10;&#10;##  Security Notes&#10;&#10;### Development Setup:&#10;- ✅ **SA account**: მხოლოდ initial setup-სთვის&#10;- ✅ **Admin account**: აპლიკაციის მუშაობისთვის&#10;- ✅ **Separate credentials**: უკეთესი უსაფრთხოება&#10;- ✅ **db_owner role**: სრული წვდომა database-ზე&#10;&#10;### Production (მომავალში):&#10;-  შეცვალეთ ყველა პაროლი&#10;-  გამოიყენეთ environment variables&#10;-  გამოიყენეთ secrets management (Azure Key Vault)&#10;-  შეზღუდეთ permissions (არა db_owner)&#10;-  Enable SSL/TLS&#10;-  Use managed identities&#10;&#10;---&#10;&#10;##  Test Scenarios&#10;&#10;### ✅ Test 1: Admin user exists&#10;```bash&#10;docker exec -it sqlserver /opt/mssql-tools/bin/sqlcmd -S localhost -U admin -P Password1234 -Q &quot;SELECT SYSTEM_USER&quot;&#10;```&#10;&#10;### ✅ Test 2: Database exists&#10;```bash&#10;docker exec -it sqlserver /opt/mssql-tools/bin/sqlcmd -S localhost -U admin -P Password1234 -Q &quot;SELECT name FROM sys.databases WHERE name='ElasticsearchDemo'&quot;&#10;```&#10;&#10;### ✅ Test 3: Admin has db_owner role&#10;```bash&#10;docker exec -it sqlserver /opt/mssql-tools/bin/sqlcmd -S localhost -U admin -P Password1234 -d ElasticsearchDemo -Q &quot;SELECT IS_MEMBER('db_owner')&quot;&#10;```&#10;&#10;### ✅ Test 4: API can connect&#10;```bash&#10;docker-compose logs api | grep -i &quot;database&quot;&#10;```&#10;&#10;### ✅ Test 5: Jobs can connect&#10;```bash&#10;docker-compose logs jobs | grep -i &quot;database&quot;&#10;```&#10;&#10;---&#10;&#10;##  Troubleshooting&#10;&#10;### ❌ &quot;Login failed for user 'admin'&quot;&#10;&#10;**მიზეზი**: Init scripts არ გაეშვა&#10;&#10;**გადაწყვეტა**:&#10;```bash&#10;docker-compose down -v&#10;docker-compose up -d&#10;docker-compose logs sqlserver  # ნახეთ &quot;Login [admin] created&quot;&#10;```&#10;&#10;### ❌ &quot;Cannot open database 'ElasticsearchDemo'&quot;&#10;&#10;**მიზეზი**: Database არ შექმნილა&#10;&#10;**გადაწყვეტა**:&#10;```bash&#10;# Manual creation&#10;docker exec -it sqlserver /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P YourStrong@Password123&#10;1&gt; CREATE DATABASE ElasticsearchDemo;&#10;2&gt; GO&#10;```&#10;&#10;### ❌ Healthcheck failing&#10;&#10;**მიზეზი**: SQL Server ჯერ არ არის ready&#10;&#10;**გადაწყვეტა**: მოითმინეთ ~60 წამი (start_period: 60s)&#10;&#10;```bash&#10;docker-compose ps  # ნახეთ &quot;starting (health: starting)&quot;&#10;# დაელოდეთ &quot;up (healthy)&quot;&#10;```&#10;&#10;### ❌ Permission denied on entrypoint.sh&#10;&#10;**მიზეზი**: File permissions (Windows line endings)&#10;&#10;**გადაწყვეტა**:&#10;```bash&#10;# Git-ში:&#10;git config core.autocrlf false&#10;&#10;# Or set execute permission (Linux/Mac)&#10;chmod +x docker-init/entrypoint.sh&#10;```&#10;&#10;---&#10;&#10;##  Connection Strings Summary&#10;&#10;###  Docker (Production-like):&#10;```&#10;Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=admin;Password=Password1234;TrustServerCertificate=True;&#10;```&#10;&#10;###  Local Development (Windows):&#10;```&#10;Server=(localdb)\MSSQLLocalDB;Database=ElasticsearchDemo;Integrated Security=True;TrustServerCertificate=True;&#10;```&#10;&#10;---&#10;&#10;## ✅ Verification Checklist&#10;&#10;- [x] `docker-compose.yml` - ყველა service იყენებს `admin` user-ს&#10;- [x] `docker-init/entrypoint.sh` - არსებობს და executable&#10;- [x] `docker-init/01-create-admin-user.sql` - SQL script ქმნის admin-ს&#10;- [x] `.env.example` - განახლებული credentials-ებით&#10;- [x] `.dockerignore` - `docker-init` დამატებული&#10;- [x] Healthcheck - იყენებს `admin` user-ს&#10;- [x] Clean volumes და restart - მზადაა&#10;&#10;---&#10;&#10;##  Ready to Go!&#10;&#10;**ყველაფერი კონფიგურირებულია და მზადაა გასაშვებად:**&#10;&#10;```bash&#10;# Start everything&#10;docker-compose down -v &amp;&amp; docker-compose up -d&#10;&#10;# Watch it work&#10;docker-compose logs -f sqlserver jobs api&#10;&#10;# Access services&#10;# API: http://localhost:5000&#10;# Kibana: http://localhost:5601&#10;# SQL: admin / Password1234&#10;```&#10;&#10;**თქვენი setup ახლა იყენებს dedicated `admin` user-ს რომელიც ავტომატურად იქმნება! **&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/DOCKER-LOCALDB-LIMITATION.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/DOCKER-LOCALDB-LIMITATION.md" />
              <option name="updatedContent" value="# ⚠️ Docker Limitations with LocalDB&#10;&#10;## პრობლემა&#10;&#10;Docker containers (Linux-based) **ვერ უკავშირდებიან** Windows LocalDB-ს:&#10;&#10;```&#10;Server=(localdb)\MSSQLLocalDB  ❌ არ იმუშავებს Docker containers-ში&#10;```&#10;&#10;### რატომ?&#10;- LocalDB არის **Windows-only** feature&#10;- Docker containers Linux-ზე მუშაობს&#10;- LocalDB არის named pipe connection (Windows-specific)&#10;&#10;---&#10;&#10;## ✅ გადაწყვეტა&#10;&#10;### Option 1: Hybrid Setup (რეკომენდებული)&#10;&#10;**გაუშვით მხოლოდ Elasticsearch და Kibana Docker-ში:**&#10;&#10;```bash&#10;# Start only infrastructure&#10;docker-compose up -d elasticsearch kibana&#10;&#10;# Run API locally&#10;cd ElasticSearch.Api&#10;dotnet run&#10;&#10;# Run Jobs locally (new terminal)&#10;cd ElasticSearch.Jobs&#10;dotnet run&#10;```&#10;&#10;✅ **LocalDB მუშაობს** (native Windows process)  &#10;✅ **Elasticsearch Docker-ში** (cross-platform)  &#10;✅ **Easy debugging**&#10;&#10;---&#10;&#10;### Option 2: Full Docker with SQL Server&#10;&#10;თუ გინდათ **ყველაფერი Docker-ში**, დაგჭირდებათ SQL Server container:&#10;&#10;```yaml&#10;services:&#10;  sqlserver:&#10;    image: mcr.microsoft.com/mssql/server:2022-latest&#10;    environment:&#10;      - SA_PASSWORD=YourStrong@Password123&#10;    ports:&#10;      - &quot;1433:1433&quot;&#10;  &#10;  api:&#10;    environment:&#10;      - ConnectionStrings__SqlServer=Server=sqlserver,1433;User Id=sa;Password=YourStrong@Password123;...&#10;```&#10;&#10;❌ **არ გამოიყენოთ Integrated Security**  &#10;✅ **გამოიყენეთ SQL Authentication**&#10;&#10;---&#10;&#10;### Option 3: Host Network Mode (არ რეკომენდირებული)&#10;&#10;```yaml&#10;api:&#10;  network_mode: &quot;host&quot;  # Windows-ზე არ მუშაობს კარგად&#10;```&#10;&#10;⚠️ **არასანდოა და არ არის portable**&#10;&#10;---&#10;&#10;##  რეკომენდაცია&#10;&#10;### Development (Windows):&#10;```bash&#10;✅ LocalDB + Integrated Security&#10;✅ Elasticsearch/Kibana → Docker&#10;✅ API/Jobs → dotnet run (locally)&#10;```&#10;&#10;**იხილეთ**: [LOCAL-SETUP.md](../LOCAL-SETUP.md)&#10;&#10;### Production / Team:&#10;```bash&#10;✅ SQL Server → Docker (SQL Auth)&#10;✅ Elasticsearch → Docker&#10;✅ Kibana → Docker&#10;✅ API → Docker&#10;✅ Jobs → Docker&#10;```&#10;&#10;**იხილეთ**: [QUICKSTART.md](../QUICKSTART.md)&#10;&#10;---&#10;&#10;##  სწრაფი დაწყება&#10;&#10;### მიმდინარე Setup (LocalDB):&#10;&#10;```bash&#10;# 1. Start infrastructure only&#10;start-local.bat&#10;# OR&#10;docker-compose up -d elasticsearch kibana&#10;&#10;# 2. Run API&#10;cd ElasticSearch.Api&#10;dotnet run&#10;&#10;# 3. Run Jobs (new terminal)&#10;cd ElasticSearch.Jobs&#10;dotnet run&#10;```&#10;&#10;**Access**:&#10;- API: http://localhost:5000&#10;- Kibana: http://localhost:5601&#10;- SQL: (localdb)\MSSQLLocalDB (SSMS/Rider)&#10;&#10;---&#10;&#10;##  თუ API/Jobs containers-ში გინდათ SQL-ის გამოყენება&#10;&#10;### გააკეთეთ შემდეგი:&#10;&#10;1. **დააკომენტეთ/წაშალეთ API და Jobs services `docker-compose.yml`-დან**&#10;&#10;2. **გაუშვით მხოლოდ infrastructure:**&#10;```bash&#10;docker-compose up -d  # მხოლოდ elasticsearch + kibana გაეშვება&#10;```&#10;&#10;3. **Run application locally:**&#10;```bash&#10;cd ElasticSearch.Api &amp;&amp; dotnet run&#10;cd ElasticSearch.Jobs &amp;&amp; dotnet run&#10;```&#10;&#10;---&#10;&#10;## ✅ Summary&#10;&#10;| Setup | SQL | Elasticsearch | API | Jobs | Complexity |&#10;|-------|-----|---------------|-----|------|------------|&#10;| **Hybrid** | LocalDB (local) | Docker | Local | Local | ⚡ Simple |&#10;| **Full Docker** | Docker | Docker | Docker | Docker |  Complex |&#10;| **Local Only** | LocalDB | Local | Local | Local |  Dev only |&#10;&#10;**თქვენი შემთხვევა: Hybrid Setup! **&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/ElasticSearch.Api/appsettings.Production.json">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/ElasticSearch.Api/appsettings.Production.json" />
              <option name="originalContent" value="{&#10;  &quot;ConnectionStrings&quot;: {&#10;    &quot;SqlServer&quot;: &quot;Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=YourStrong@Password123;TrustServerCertificate=True;&quot;&#10;  },&#10;  &quot;Elasticsearch&quot;: {&#10;    &quot;Uri&quot;: &quot;http://elasticsearch:9200&quot;&#10;  },&#10;  &quot;Logging&quot;: {&#10;    &quot;LogLevel&quot;: {&#10;      &quot;Default&quot;: &quot;Information&quot;,&#10;      &quot;Microsoft.AspNetCore&quot;: &quot;Warning&quot;&#10;    }&#10;  },&#10;  &quot;AllowedHosts&quot;: &quot;*&quot;&#10;}&#10;&#10;" />
              <option name="updatedContent" value="{&#10;  &quot;ConnectionStrings&quot;: {&#10;    &quot;SqlServer&quot;: &quot;Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=Password1234!;TrustServerCertificate=True;&quot;&#10;  },&#10;  &quot;Elasticsearch&quot;: {&#10;    &quot;Uri&quot;: &quot;http://elasticsearch:9200&quot;&#10;  },&#10;  &quot;Logging&quot;: {&#10;    &quot;LogLevel&quot;: {&#10;      &quot;Default&quot;: &quot;Information&quot;,&#10;      &quot;Microsoft.AspNetCore&quot;: &quot;Warning&quot;&#10;    }&#10;  },&#10;  &quot;AllowedHosts&quot;: &quot;*&quot;&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/ElasticSearch.Core/Services/SqlToElasticsearchSyncService.cs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/ElasticSearch.Core/Services/SqlToElasticsearchSyncService.cs" />
              <option name="originalContent" value="using Nest;&#10;using Microsoft.Data.SqlClient;&#10;using Dapper;&#10;using ElasticSearch.Core.Models;&#10;&#10;namespace ElasticSearch.Core.Services;&#10;&#10;public class SqlToElasticsearchSyncService&#10;{&#10;    private readonly ElasticClient _elasticClient;&#10;    private readonly string _sqlConnectionString;&#10;&#10;    public SqlToElasticsearchSyncService(ElasticClient elasticClient, string sqlConnectionString)&#10;    {&#10;        _elasticClient = elasticClient;&#10;        _sqlConnectionString = sqlConnectionString;&#10;    }&#10;&#10;    public async Task FullSyncAsync()&#10;    {&#10;        var startTime = DateTime.Now;&#10;        Console.WriteLine($&quot; [FULL SYNC] Starting at {startTime:HH:mm:ss}...&quot;);&#10;        &#10;        try&#10;        {&#10;            await EnsureIndexExistsAsync();&#10;            Console.WriteLine(&quot;  ✓ Index ensured&quot;);&#10;            &#10;            var products = await GetProductsFromSqlAsync();&#10;            Console.WriteLine($&quot;   Found {products.Count} products in SQL Server&quot;);&#10;            &#10;            if (products.Count &gt; 0)&#10;            {&#10;                await BulkIndexToElasticsearchAsync(products);&#10;                Console.WriteLine($&quot;  ✅ Indexed {products.Count} products to Elasticsearch&quot;);&#10;            }&#10;            else&#10;            {&#10;                Console.WriteLine(&quot;  ⚠️  No products found to sync&quot;);&#10;            }&#10;            &#10;            var duration = (DateTime.Now - startTime).TotalSeconds;&#10;            Console.WriteLine($&quot;✅ [FULL SYNC] Completed in {duration:F2}s&quot;);&#10;        }&#10;        catch (Exception ex)&#10;        {&#10;            Console.WriteLine($&quot;❌ [FULL SYNC] Failed: {ex.Message}&quot;);&#10;            Console.WriteLine($&quot;   Stack: {ex.StackTrace}&quot;);&#10;            throw;&#10;        }&#10;    }&#10;&#10;    public async Task IncrementalSyncAsync()&#10;    {&#10;        Console.WriteLine(&quot; [INCREMENTAL SYNC] Starting...&quot;);&#10;        &#10;        var lastSync = await GetLastSyncTimestampAsync();&#10;        Console.WriteLine($&quot; Last sync: {lastSync:yyyy-MM-dd HH:mm:ss}&quot;);&#10;&#10;        var changes = await GetChangedProductsFromSqlAsync(lastSync);&#10;        Console.WriteLine($&quot; Found {changes.Count} changes&quot;);&#10;&#10;        if (changes.Count == 0)&#10;        {&#10;            await UpdateLastSyncTimestampAsync(DateTime.UtcNow);&#10;            Console.WriteLine(&quot;✅ No changes&quot;);&#10;            return;&#10;        }&#10;&#10;        foreach (var change in changes)&#10;        {&#10;            if (change.IsDeleted)&#10;            {&#10;                await _elasticClient.DeleteAsync&lt;Product&gt;(change.Id.ToString(), d =&gt; d.Index(&quot;products&quot;));&#10;                Console.WriteLine($&quot;  ✗ Deleted product {change.Id}&quot;);&#10;            }&#10;            else&#10;            {&#10;                var product = await GetProductDetailFromSqlAsync(change.Id);&#10;                if (product != null)&#10;                {&#10;                    await _elasticClient.IndexAsync(product, i =&gt; i.Index(&quot;products&quot;).Id(product.Id));&#10;                    Console.WriteLine($&quot;  ✓ Synced product {change.Id}&quot;);&#10;                }&#10;            }&#10;        }&#10;&#10;        await UpdateLastSyncTimestampAsync(DateTime.UtcNow);&#10;        Console.WriteLine(&quot;✅ [INCREMENTAL SYNC] Completed&quot;);&#10;    }&#10;&#10;    private async Task EnsureIndexExistsAsync()&#10;    {&#10;        var exists = await _elasticClient.Indices.ExistsAsync(&quot;products&quot;);&#10;        if (!exists.Exists)&#10;        {&#10;            await _elasticClient.Indices.CreateAsync(&quot;products&quot;, c =&gt; c&#10;                .Map&lt;Product&gt;(m =&gt; m.AutoMap())&#10;            );&#10;        }&#10;    }&#10;&#10;    private async Task&lt;List&lt;Product&gt;&gt; GetProductsFromSqlAsync()&#10;    {&#10;        await using var connection = new SqlConnection(_sqlConnectionString);&#10;        &#10;        var sql = &quot;SELECT * FROM Products WHERE IsActive = 1&quot;;&#10;        var dtos = (await connection.QueryAsync&lt;ProductDto&gt;(sql)).ToList();&#10;        &#10;        return dtos.Select(dto =&gt; new Product&#10;        {&#10;            Id = dto.Id.ToString(),&#10;            Name = dto.Name,&#10;            Description = dto.Description,&#10;            Price = dto.Price,&#10;            Stock = dto.Stock,&#10;            Category = dto.Category,&#10;            Tags = string.IsNullOrEmpty(dto.Tags) ? new List&lt;string&gt;() : dto.Tags.Split(',').ToList(),&#10;            CreatedDate = dto.CreatedDate,&#10;            IsActive = dto.IsActive,&#10;            Specifications = new ProductSpecs { Brand = dto.Brand, Model = dto.Model }&#10;        }).ToList();&#10;    }&#10;&#10;    private async Task&lt;List&lt;ProductChange&gt;&gt; GetChangedProductsFromSqlAsync(DateTime lastSync)&#10;    {&#10;        await using var connection = new SqlConnection(_sqlConnectionString);&#10;        var sql = &quot;SELECT Id, UpdatedAt, CreatedDate, IsDeleted FROM Products WHERE UpdatedAt &gt; @LastSync&quot;;&#10;        return (await connection.QueryAsync&lt;ProductChange&gt;(sql, new { LastSync = lastSync })).ToList();&#10;    }&#10;&#10;    private async Task&lt;Product?&gt; GetProductDetailFromSqlAsync(int id)&#10;    {&#10;        await using var connection = new SqlConnection(_sqlConnectionString);&#10;        var dto = await connection.QueryFirstOrDefaultAsync&lt;ProductDto&gt;(&quot;SELECT * FROM Products WHERE Id = @Id&quot;, new { Id = id });&#10;        &#10;        if (dto == null) return null;&#10;        &#10;        return new Product&#10;        {&#10;            Id = dto.Id.ToString(),&#10;            Name = dto.Name,&#10;            Description = dto.Description,&#10;            Price = dto.Price,&#10;            Stock = dto.Stock,&#10;            Category = dto.Category,&#10;            Tags = string.IsNullOrEmpty(dto.Tags) ? new List&lt;string&gt;() : dto.Tags.Split(',').ToList(),&#10;            CreatedDate = dto.CreatedDate,&#10;            IsActive = dto.IsActive,&#10;            Specifications = new ProductSpecs { Brand = dto.Brand, Model = dto.Model }&#10;        };&#10;    }&#10;&#10;    private async Task BulkIndexToElasticsearchAsync(List&lt;Product&gt; products)&#10;    {&#10;        const int batchSize = 1000;&#10;        var batches = products.Chunk(batchSize).ToList();&#10;        &#10;        Console.WriteLine($&quot;   Indexing {products.Count} products in {batches.Count} batch(es)...&quot;);&#10;        &#10;        int processed = 0;&#10;        int successCount = 0;&#10;        int errorCount = 0;&#10;        &#10;        foreach (var batch in batches)&#10;        {&#10;            var response = await _elasticClient.BulkAsync(b =&gt; b.Index(&quot;products&quot;).IndexMany(batch));&#10;            &#10;            if (!response.IsValid)&#10;            {&#10;                errorCount += batch.Length;&#10;                Console.WriteLine($&quot;  ❌ Bulk index failed: {response.OriginalException?.Message}&quot;);&#10;                Console.WriteLine($&quot;     Server error: {response.ServerError?.Error?.Reason}&quot;);&#10;                Console.WriteLine($&quot;     Debug info: {response.DebugInformation}&quot;);&#10;            }&#10;            else if (response.Errors)&#10;            {&#10;                // Some items failed&#10;                var itemsWithErrors = response.ItemsWithErrors.ToList();&#10;                errorCount += itemsWithErrors.Count;&#10;                successCount += batch.Length - itemsWithErrors.Count;&#10;                &#10;                foreach (var item in itemsWithErrors.Take(3)) // Show first 3 errors&#10;                {&#10;                    Console.WriteLine($&quot;  ⚠️  Item error: {item.Error?.Reason ?? &quot;Unknown&quot;}&quot;);&#10;                }&#10;&#10;                if (itemsWithErrors.Count &gt; 3)&#10;                {&#10;                    Console.WriteLine($&quot;  ⚠️  ... and {itemsWithErrors.Count - 3} more errors&quot;);&#10;                }&#10;            }&#10;            else&#10;            {&#10;                successCount += batch.Length;&#10;            }&#10;            &#10;            processed += batch.Length;&#10;            Console.WriteLine($&quot;    → Processed {processed}/{products.Count} products (✓ {successCount} success, ✗ {errorCount} errors)&quot;);&#10;            &#10;            await Task.Delay(100);&#10;        }&#10;    }&#10;&#10;    private async Task&lt;DateTime&gt; GetLastSyncTimestampAsync()&#10;    {&#10;        try&#10;        {&#10;            var response = await _elasticClient.GetAsync&lt;SyncMetadata&gt;(&quot;last_sync&quot;, g =&gt; g.Index(&quot;sync_metadata&quot;));&#10;            return response.Found &amp;&amp; response.Source != null ? response.Source.LastSync : DateTime.MinValue;&#10;        }&#10;        catch&#10;        {&#10;            return DateTime.MinValue;&#10;        }&#10;    }&#10;&#10;    private async Task UpdateLastSyncTimestampAsync(DateTime timestamp)&#10;    {&#10;        var exists = await _elasticClient.Indices.ExistsAsync(&quot;sync_metadata&quot;);&#10;        if (!exists.Exists)&#10;        {&#10;            await _elasticClient.Indices.CreateAsync(&quot;sync_metadata&quot;);&#10;        }&#10;&#10;        await _elasticClient.IndexAsync(new SyncMetadata&#10;        {&#10;            Id = &quot;last_sync&quot;,&#10;            LastSync = timestamp,&#10;            SyncType = &quot;incremental&quot;&#10;        }, i =&gt; i.Index(&quot;sync_metadata&quot;).Id(&quot;last_sync&quot;));&#10;    }&#10;}&#10;&#10;" />
              <option name="updatedContent" value="using Nest;&#10;using Microsoft.Data.SqlClient;&#10;using Dapper;&#10;using ElasticSearch.Core.Models;&#10;&#10;namespace ElasticSearch.Core.Services;&#10;&#10;public class SqlToElasticsearchSyncService&#10;{&#10;    private readonly ElasticClient _elasticClient;&#10;    private readonly string _sqlConnectionString;&#10;&#10;    public SqlToElasticsearchSyncService(ElasticClient elasticClient, string sqlConnectionString)&#10;    {&#10;        _elasticClient = elasticClient;&#10;        _sqlConnectionString = sqlConnectionString;&#10;    }&#10;&#10;    public async Task FullSyncAsync()&#10;    {&#10;        var startTime = DateTime.Now;&#10;        Console.WriteLine($&quot; [FULL SYNC] Starting at {startTime:HH:mm:ss}...&quot;);&#10;        &#10;        try&#10;        {&#10;            await EnsureIndexExistsAsync();&#10;            Console.WriteLine(&quot;  ✓ Index ensured&quot;);&#10;            &#10;            var products = await GetProductsFromSqlAsync();&#10;            Console.WriteLine($&quot;   Found {products.Count} products in SQL Server&quot;);&#10;            &#10;            if (products.Count &gt; 0)&#10;            {&#10;                await BulkIndexToElasticsearchAsync(products);&#10;                Console.WriteLine($&quot;  ✅ Indexed {products.Count} products to Elasticsearch&quot;);&#10;            }&#10;            else&#10;            {&#10;                Console.WriteLine(&quot;  ⚠️  No products found to sync&quot;);&#10;            }&#10;            &#10;            // Update last sync timestamp&#10;            await UpdateLastSyncTimestampAsync(DateTime.UtcNow);&#10;            Console.WriteLine(&quot;  ✓ Updated last sync timestamp&quot;);&#10;            &#10;            var duration = (DateTime.Now - startTime).TotalSeconds;&#10;            Console.WriteLine($&quot;✅ [FULL SYNC] Completed in {duration:F2}s&quot;);&#10;        }&#10;        catch (Exception ex)&#10;        {&#10;            Console.WriteLine($&quot;❌ [FULL SYNC] Failed: {ex.Message}&quot;);&#10;            Console.WriteLine($&quot;   Stack: {ex.StackTrace}&quot;);&#10;            throw;&#10;        }&#10;    }&#10;&#10;    public async Task IncrementalSyncAsync()&#10;    {&#10;        var startTime = DateTime.Now;&#10;        Console.WriteLine($&quot; [INCREMENTAL SYNC] Starting at {startTime:HH:mm:ss}...&quot;);&#10;        &#10;        try&#10;        {&#10;            var lastSync = await GetLastSyncTimestampAsync();&#10;            var timeSinceLastSync = DateTime.UtcNow - lastSync;&#10;            &#10;            Console.WriteLine($&quot;   Last sync: {lastSync:yyyy-MM-dd HH:mm:ss} UTC ({timeSinceLastSync.TotalMinutes:F1} minutes ago)&quot;);&#10;            &#10;            var changes = await GetChangedProductsFromSqlAsync(lastSync);&#10;            Console.WriteLine($&quot;   Found {changes.Count} changes since last sync&quot;);&#10;            &#10;            if (changes.Count == 0)&#10;            {&#10;                await UpdateLastSyncTimestampAsync(DateTime.UtcNow);&#10;                Console.WriteLine(&quot;  ✅ No changes to sync&quot;);&#10;                var duration = (DateTime.Now - startTime).TotalSeconds;&#10;                Console.WriteLine($&quot;✅ [INCREMENTAL SYNC] Completed in {duration:F2}s&quot;);&#10;                return;&#10;            }&#10;&#10;            int syncedCount = 0;&#10;            int deletedCount = 0;&#10;            &#10;            foreach (var change in changes)&#10;            {&#10;                if (change.IsDeleted)&#10;                {&#10;                    await _elasticClient.DeleteAsync&lt;Product&gt;(change.Id.ToString(), d =&gt; d.Index(&quot;products&quot;));&#10;                    deletedCount++;&#10;                    Console.WriteLine($&quot;  ✗ Deleted product {change.Id}&quot;);&#10;                }&#10;                else&#10;                {&#10;                    var product = await GetProductDetailFromSqlAsync(change.Id);&#10;                    if (product != null)&#10;                    {&#10;                        await _elasticClient.IndexAsync(product, i =&gt; i.Index(&quot;products&quot;).Id(product.Id));&#10;                        syncedCount++;&#10;                        Console.WriteLine($&quot;  ✓ Synced product {change.Id}: {product.Name}&quot;);&#10;                    }&#10;                }&#10;            }&#10;&#10;            await UpdateLastSyncTimestampAsync(DateTime.UtcNow);&#10;            &#10;            var totalDuration = (DateTime.Now - startTime).TotalSeconds;&#10;            Console.WriteLine($&quot;   Summary: {syncedCount} updated, {deletedCount} deleted&quot;);&#10;            Console.WriteLine($&quot;✅ [INCREMENTAL SYNC] Completed in {totalDuration:F2}s&quot;);&#10;        }&#10;        catch (Exception ex)&#10;        {&#10;            Console.WriteLine($&quot;❌ [INCREMENTAL SYNC] Failed: {ex.Message}&quot;);&#10;            Console.WriteLine($&quot;   Stack: {ex.StackTrace}&quot;);&#10;            throw;&#10;        }&#10;    }&#10;&#10;    private async Task EnsureIndexExistsAsync()&#10;    {&#10;        var exists = await _elasticClient.Indices.ExistsAsync(&quot;products&quot;);&#10;        if (!exists.Exists)&#10;        {&#10;            await _elasticClient.Indices.CreateAsync(&quot;products&quot;, c =&gt; c&#10;                .Map&lt;Product&gt;(m =&gt; m.AutoMap())&#10;            );&#10;        }&#10;    }&#10;&#10;    private async Task&lt;List&lt;Product&gt;&gt; GetProductsFromSqlAsync()&#10;    {&#10;        await using var connection = new SqlConnection(_sqlConnectionString);&#10;        &#10;        var sql = &quot;SELECT * FROM Products WHERE IsActive = 1&quot;;&#10;        var dtos = (await connection.QueryAsync&lt;ProductDto&gt;(sql)).ToList();&#10;        &#10;        return dtos.Select(dto =&gt; new Product&#10;        {&#10;            Id = dto.Id.ToString(),&#10;            Name = dto.Name,&#10;            Description = dto.Description,&#10;            Price = dto.Price,&#10;            Stock = dto.Stock,&#10;            Category = dto.Category,&#10;            Tags = string.IsNullOrEmpty(dto.Tags) ? new List&lt;string&gt;() : dto.Tags.Split(',').ToList(),&#10;            CreatedDate = dto.CreatedDate,&#10;            IsActive = dto.IsActive,&#10;            Specifications = new ProductSpecs { Brand = dto.Brand, Model = dto.Model }&#10;        }).ToList();&#10;    }&#10;&#10;    private async Task&lt;List&lt;ProductChange&gt;&gt; GetChangedProductsFromSqlAsync(DateTime lastSync)&#10;    {&#10;        await using var connection = new SqlConnection(_sqlConnectionString);&#10;        var sql = &quot;SELECT Id, UpdatedAt, CreatedDate, IsDeleted FROM Products WHERE UpdatedAt &gt; @LastSync&quot;;&#10;        return (await connection.QueryAsync&lt;ProductChange&gt;(sql, new { LastSync = lastSync })).ToList();&#10;    }&#10;&#10;    private async Task&lt;Product?&gt; GetProductDetailFromSqlAsync(int id)&#10;    {&#10;        await using var connection = new SqlConnection(_sqlConnectionString);&#10;        var dto = await connection.QueryFirstOrDefaultAsync&lt;ProductDto&gt;(&quot;SELECT * FROM Products WHERE Id = @Id&quot;, new { Id = id });&#10;        &#10;        if (dto == null) return null;&#10;        &#10;        return new Product&#10;        {&#10;            Id = dto.Id.ToString(),&#10;            Name = dto.Name,&#10;            Description = dto.Description,&#10;            Price = dto.Price,&#10;            Stock = dto.Stock,&#10;            Category = dto.Category,&#10;            Tags = string.IsNullOrEmpty(dto.Tags) ? new List&lt;string&gt;() : dto.Tags.Split(',').ToList(),&#10;            CreatedDate = dto.CreatedDate,&#10;            IsActive = dto.IsActive,&#10;            Specifications = new ProductSpecs { Brand = dto.Brand, Model = dto.Model }&#10;        };&#10;    }&#10;&#10;    private async Task BulkIndexToElasticsearchAsync(List&lt;Product&gt; products)&#10;    {&#10;        const int batchSize = 1000;&#10;        var batches = products.Chunk(batchSize).ToList();&#10;        &#10;        Console.WriteLine($&quot;   Indexing {products.Count} products in {batches.Count} batch(es)...&quot;);&#10;        &#10;        int processed = 0;&#10;        int successCount = 0;&#10;        int errorCount = 0;&#10;        &#10;        foreach (var batch in batches)&#10;        {&#10;            var response = await _elasticClient.BulkAsync(b =&gt; b.Index(&quot;products&quot;).IndexMany(batch));&#10;            &#10;            // Don't trust response.IsValid or response.Errors flags&#10;            // They are unreliable with NEST library&#10;            // Instead, check actual HTTP status codes&#10;            &#10;            if (response.Items != null &amp;&amp; response.Items.Any())&#10;            {&#10;                foreach (var item in response.Items)&#10;                {&#10;                    // Status 200 (OK) or 201 (Created) = SUCCESS&#10;                    // Anything else = ERROR&#10;                    if (item.Status &gt;= 200 &amp;&amp; item.Status &lt; 300)&#10;                    {&#10;                        successCount++;&#10;                    }&#10;                    else&#10;                    {&#10;                        errorCount++;&#10;                        if (errorCount &lt;= 3)&#10;                        {&#10;                            var errorMsg = item.Error?.Reason ?? &quot;Unknown error&quot;;&#10;                            Console.WriteLine($&quot;  ⚠️  Item {item.Id} failed (HTTP {item.Status}): {errorMsg}&quot;);&#10;                        }&#10;                    }&#10;                }&#10;                &#10;                if (errorCount &gt; 3)&#10;                {&#10;                    Console.WriteLine($&quot;  ⚠️  ... and {errorCount - 3} more errors&quot;);&#10;                }&#10;            }&#10;            else if (response.OriginalException != null)&#10;            {&#10;                // Complete failure - network/connection error&#10;                errorCount += batch.Length;&#10;                Console.WriteLine($&quot;  ❌ Bulk request exception: {response.OriginalException.Message}&quot;);&#10;            }&#10;            else&#10;            {&#10;                // No items in response but no exception - assume success&#10;                successCount += batch.Length;&#10;            }&#10;            &#10;            processed += batch.Length;&#10;            &#10;            if (errorCount &gt; 0)&#10;            {&#10;                Console.WriteLine($&quot;    → Processed {processed}/{products.Count} (✓ {successCount} success, ✗ {errorCount} failed)&quot;);&#10;            }&#10;            else&#10;            {&#10;                Console.WriteLine($&quot;    → Processed {processed}/{products.Count} (✓ {successCount} success)&quot;);&#10;            }&#10;            &#10;            await Task.Delay(100);&#10;        }&#10;    }&#10;&#10;    private async Task&lt;DateTime&gt; GetLastSyncTimestampAsync()&#10;    {&#10;        try&#10;        {&#10;            var exists = await _elasticClient.Indices.ExistsAsync(&quot;sync_metadata&quot;);&#10;            if (!exists.Exists)&#10;            {&#10;                // First run - sync everything from last 24 hours&#10;                return DateTime.UtcNow.AddDays(-1);&#10;            }&#10;            &#10;            var response = await _elasticClient.GetAsync&lt;SyncMetadata&gt;(&quot;last_sync&quot;, g =&gt; g.Index(&quot;sync_metadata&quot;));&#10;            &#10;            if (response.Found &amp;&amp; response.Source != null)&#10;            {&#10;                return response.Source.LastSync;&#10;            }&#10;            &#10;            // Index exists but no last_sync document - sync from last 24 hours&#10;            return DateTime.UtcNow.AddDays(-1);&#10;        }&#10;        catch&#10;        {&#10;            // On error, sync from last 24 hours to be safe&#10;            return DateTime.UtcNow.AddDays(-1);&#10;        }&#10;    }&#10;&#10;    private async Task UpdateLastSyncTimestampAsync(DateTime timestamp)&#10;    {&#10;        var exists = await _elasticClient.Indices.ExistsAsync(&quot;sync_metadata&quot;);&#10;        if (!exists.Exists)&#10;        {&#10;            await _elasticClient.Indices.CreateAsync(&quot;sync_metadata&quot;);&#10;        }&#10;&#10;        await _elasticClient.IndexAsync(new SyncMetadata&#10;        {&#10;            Id = &quot;last_sync&quot;,&#10;            LastSync = timestamp,&#10;            SyncType = &quot;incremental&quot;&#10;        }, i =&gt; i.Index(&quot;sync_metadata&quot;).Id(&quot;last_sync&quot;));&#10;    }&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/QUICK_START_3_STEPS.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/QUICK_START_3_STEPS.md" />
              <option name="originalContent" value="# ⚡ სწრაფი დასტარტვა - 3 ნაბიჯი&#10;&#10;##  რას აკეთებს ეს სისტემა?&#10;&#10;აპლიკაცია **ავტომატურად**:&#10;1. ✅ ქმნის SQL Server მონაცემთა ბაზას&#10;2. ✅ ატვირთავს 15 სატესტო პროდუქტს&#10;3. ✅ სინქრონიზებას უკეთებს Elasticsearch-თან&#10;4. ✅ უზრუნველყოფს real-time სინქრონიზაციას&#10;&#10;---&#10;&#10;##  3 ნაბიჯი დასტარტვისთვის&#10;&#10;### 1️⃣ Infrastructure (Elasticsearch + Kibana)&#10;&#10;**Double-click:** `start-infrastructure.bat`&#10;&#10;ან terminal-ში:&#10;```cmd&#10;docker-compose up -d&#10;```&#10;&#10;⏱️ დაელოდეთ 30 წამს Elasticsearch-ის ჩასატვირთად&#10;&#10;---&#10;&#10;### 2️⃣ API (ახალ terminal-ში)&#10;&#10;**Double-click:** `start-api.bat`&#10;&#10;ან terminal-ში:&#10;```cmd&#10;cd ElasticSearch.Api&#10;dotnet run&#10;```&#10;&#10;რას აკეთებს:&#10;- ✅ ქმნის `ElasticsearchDemo` მონაცემთა ბაზას&#10;- ✅ ქმნის `Products` ცხრილს&#10;- ✅ ატვირთავს 15 სატესტო პროდუქტს&#10;&#10;დაეშვება: **http://localhost:5000** (Swagger UI)&#10;&#10;---&#10;&#10;### 3️⃣ Jobs - Background Sync (ახალ terminal-ში)&#10;&#10;**Double-click:** `start-jobs.bat`&#10;&#10;ან terminal-ში:&#10;```cmd&#10;cd ElasticSearch.Jobs&#10;dotnet run&#10;```&#10;&#10;რას აკეთებს:&#10;- ✅ ასინქრონებს მონაცემებს SQL Server → Elasticsearch&#10;- ✅ აგრძელებს სინქრონიზაციას ყოველ 5 წუთში&#10;&#10;---&#10;&#10;## ✨ ეს იყო ყველაფერი!&#10;&#10;ახლა თქვენ გაქვთ:&#10;-  SQL Server-ში 15 პროდუქტი&#10;-  Elasticsearch-ში იგივე 15 პროდუქტი&#10;-  მომუშავე REST API&#10;-  ავტომატური სინქრონიზაცია&#10;&#10;---&#10;&#10;##  Links&#10;&#10;- **API Swagger**: http://localhost:5000&#10;- **Elasticsearch**: http://localhost:9200&#10;- **Kibana**: http://localhost:5601&#10;&#10;---&#10;&#10;##  სწრაფი ტესტი&#10;&#10;### Browser-ში:&#10;&#10;გახსენით: http://localhost:5000&#10;&#10;Swagger-ში სცადეთ:&#10;- `GET /api/products/search` - ყველა პროდუქტის ნახვა&#10;- `GET /api/products/search?query=laptop` - ძებნა&#10;&#10;---&#10;&#10;##  მაგალითები&#10;&#10;### 1. ყველა პროდუქტის ნახვა&#10;```&#10;http://localhost:5000/api/products/search&#10;```&#10;&#10;### 2. ძებნა &quot;laptop&quot;&#10;```&#10;http://localhost:5000/api/products/search?query=laptop&#10;```&#10;&#10;### 3. კატეგორიით ფილტრი&#10;```&#10;http://localhost:5000/api/products/search?category=Laptops&#10;```&#10;&#10;### 4. ფასის დიაპაზონი&#10;```&#10;http://localhost:5000/api/products/search?minPrice=1000&amp;maxPrice=3000&#10;```&#10;&#10;---&#10;&#10;##  გაჩერება&#10;&#10;**Double-click:** `stop-all.bat`&#10;&#10;ან:&#10;```cmd&#10;docker-compose down&#10;```&#10;&#10;API და Jobs - უბრალოდ Ctrl+C terminal-ში&#10;&#10;---&#10;&#10;##  პრობლემა?&#10;&#10;### SQL Server არ მუშაობს:&#10;```cmd&#10;# შეამოწმეთ:&#10;sqlcmd -S localhost -Q &quot;SELECT 1&quot;&#10;```&#10;&#10;### Elasticsearch არ მუშაობს:&#10;```cmd&#10;# შეამოწმეთ:&#10;curl http://localhost:9200&#10;```&#10;&#10;### მონაცემები არ ჩაიტვირთა:&#10;```cmd&#10;# გადაეშვით API თავიდან (Ctrl+C და dotnet run)&#10;# API ავტომატურად შექმნის ყველაფერს&#10;&#10;# შემდეგ გადაეშვით Jobs თავიდან&#10;# Jobs ავტომატურად გააკეთებს სინქრონიზაციას&#10;```&#10;&#10;---&#10;&#10;##  დეტალური გაიდი&#10;&#10;მეტი ინფორმაციისთვის:&#10;- [AUTO_SYNC_GUIDE.md](AUTO_SYNC_GUIDE.md) - დეტალური ავტომატური სინქრონიზაციის გაიდი&#10;- [README_UPDATED.md](README_UPDATED.md) - სრული დოკუმენტაცია&#10;&#10;---&#10;&#10;**იმდენად მარტივია! **&#10;&#10;" />
              <option name="updatedContent" value="# ⚡ სწრაფი დასტარტვა - 3 ნაბიჯი&#10;&#10;## ⚠️ პირობები (Prerequisites)&#10;&#10;**აუცილებელია გაშვებული:**&#10;1. ✅ **SQL Server** (LocalDB ან Express ან Full version)&#10;   - შეამოწმეთ: `sqlcmd -S localhost -E -Q &quot;SELECT 1&quot;`&#10;   - თუ არ მუშაობს, გაუშვით SQL Server Service&#10;2. ✅ **Docker Desktop** (Elasticsearch-ისთვის)&#10;&#10;---&#10;&#10;##  რას აკეთებს ეს სისტემა?&#10;&#10;აპლიკაცია **ავტომატურად**:&#10;1. ✅ ქმნის SQL Server მონაცემთა ბაზას&#10;2. ✅ ატვირთავს 15 სატესტო პროდუქტს&#10;3. ✅ სინქრონიზებას უკეთებს Elasticsearch-თან&#10;4. ✅ უზრუნველყოფს real-time სინქრონიზაციას&#10;&#10;---&#10;&#10;##  3 ნაბიჯი დასტარტვისთვის&#10;&#10;### 1️⃣ Infrastructure (Elasticsearch + Kibana)&#10;&#10;**Double-click:** `start-infrastructure.bat`&#10;&#10;ან terminal-ში:&#10;```cmd&#10;docker-compose up -d&#10;```&#10;&#10;⏱️ დაელოდეთ 30 წამს Elasticsearch-ის ჩასატვირთად&#10;&#10;---&#10;&#10;### 2️⃣ API (ახალ terminal-ში)&#10;&#10;**Double-click:** `start-api.bat`&#10;&#10;ან terminal-ში:&#10;```cmd&#10;cd ElasticSearch.Api&#10;dotnet run&#10;```&#10;&#10;რას აკეთებს:&#10;- ✅ ქმნის `ElasticsearchDemo` მონაცემთა ბაზას&#10;- ✅ ქმნის `Products` ცხრილს&#10;- ✅ ატვირთავს 15 სატესტო პროდუქტს&#10;&#10;დაეშვება: **http://localhost:5000** (Swagger UI)&#10;&#10;---&#10;&#10;### 3️⃣ Jobs - Background Sync (ახალ terminal-ში)&#10;&#10;**Double-click:** `start-jobs.bat`&#10;&#10;ან terminal-ში:&#10;```cmd&#10;cd ElasticSearch.Jobs&#10;dotnet run&#10;```&#10;&#10;რას აკეთებს:&#10;- ✅ ასინქრონებს მონაცემებს SQL Server → Elasticsearch&#10;- ✅ აგრძელებს სინქრონიზაციას ყოველ 5 წუთში&#10;&#10;---&#10;&#10;## ✨ ეს იყო ყველაფერი!&#10;&#10;ახლა თქვენ გაქვთ:&#10;-  SQL Server-ში 15 პროდუქტი&#10;-  Elasticsearch-ში იგივე 15 პროდუქტი&#10;-  მომუშავე REST API&#10;-  ავტომატური სინქრონიზაცია&#10;&#10;---&#10;&#10;##  Links&#10;&#10;- **API Swagger**: http://localhost:5000&#10;- **Elasticsearch**: http://localhost:9200&#10;- **Kibana**: http://localhost:5601&#10;&#10;---&#10;&#10;##  სწრაფი ტესტი&#10;&#10;### Browser-ში:&#10;&#10;გახსენით: http://localhost:5000&#10;&#10;Swagger-ში სცადეთ:&#10;- `GET /api/products/search` - ყველა პროდუქტის ნახვა&#10;- `GET /api/products/search?query=laptop` - ძებნა&#10;&#10;---&#10;&#10;##  მაგალითები&#10;&#10;### 1. ყველა პროდუქტის ნახვა&#10;```&#10;http://localhost:5000/api/products/search&#10;```&#10;&#10;### 2. ძებნა &quot;laptop&quot;&#10;```&#10;http://localhost:5000/api/products/search?query=laptop&#10;```&#10;&#10;### 3. კატეგორიით ფილტრი&#10;```&#10;http://localhost:5000/api/products/search?category=Laptops&#10;```&#10;&#10;### 4. ფასის დიაპაზონი&#10;```&#10;http://localhost:5000/api/products/search?minPrice=1000&amp;maxPrice=3000&#10;```&#10;&#10;---&#10;&#10;##  გაჩერება&#10;&#10;**Double-click:** `stop-all.bat`&#10;&#10;ან:&#10;```cmd&#10;docker-compose down&#10;```&#10;&#10;API და Jobs - უბრალოდ Ctrl+C terminal-ში&#10;&#10;---&#10;&#10;##  პრობლემა?&#10;&#10;### SQL Server არ მუშაობს:&#10;```cmd&#10;# შეამოწმეთ:&#10;sqlcmd -S localhost -E -Q &quot;SELECT 1&quot;&#10;```&#10;&#10;თუ არ მუშაობს:&#10;1. გახსენით **Services** (Windows Services)&#10;2. იპოვეთ **SQL Server** service&#10;3. დააჭირეთ **Start**&#10;&#10;ან SSMS-დან:&#10;- დააჭირეთ Connect და შეამოწმეთ კავშირი&#10;&#10;### Elasticsearch არ მუშაობს:&#10;```cmd&#10;# შეამოწმეთ:&#10;curl http://localhost:9200&#10;```&#10;&#10;### მონაცემები არ ჩაიტვირთა:&#10;```cmd&#10;# გადაეშვით API თავიდან (Ctrl+C და dotnet run)&#10;# API ავტომატურად შექმნის ყველაფერს&#10;&#10;# შემდეგ გადაეშვით Jobs თავიდან&#10;# Jobs ავტომატურად გააკეთებს სინქრონიზაციას&#10;```&#10;&#10;---&#10;&#10;##  დეტალური გაიდი&#10;&#10;მეტი ინფორმაციისთვის:&#10;- [AUTO_SYNC_GUIDE.md](AUTO_SYNC_GUIDE.md) - დეტალური ავტომატური სინქრონიზაციის გაიდი&#10;- [README_UPDATED.md](README_UPDATED.md) - სრული დოკუმენტაცია&#10;&#10;---&#10;&#10;**იმდენად მარტივია! **&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/README_SIMPLE.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/README_SIMPLE.md" />
              <option name="originalContent" value="#  Elasticsearch Demo - ავტომატური სინქრონიზაცია&#10;&#10;## ⚡ რას აკეთებს?&#10;&#10;**დასტარტვისას ავტომატურად:**&#10;- ✅ ქმნის SQL Server მონაცემთა ბაზას (`ElasticsearchDemo`)&#10;- ✅ ქმნის `Products` ცხრილს&#10;- ✅ ატვირთავს 15 სატესტო პროდუქტს (თუ ცხრილი ცარიელია)&#10;- ✅ სინქრონიზებას უკეთებს Elasticsearch-თან&#10;- ✅ აგრძელებს real-time სინქრონიზაციას ყოველ 5 წუთში&#10;&#10;---&#10;&#10;##  სწრაფი დასტარტვა&#10;&#10;### 1️⃣ Elasticsearch + Kibana&#10;```cmd&#10;start-infrastructure.bat&#10;```&#10;ან: `docker-compose up -d`&#10;&#10;⏱️ დაელოდეთ 30 წამს&#10;&#10;### 2️⃣ API (ახალ terminal)&#10;```cmd&#10;start-api.bat&#10;```&#10;ან: `cd ElasticSearch.Api &amp;&amp; dotnet run`&#10;&#10;→ **http://localhost:5000** (Swagger)&#10;&#10;### 3️⃣ Jobs (ახალ terminal)&#10;```cmd&#10;start-jobs.bat&#10;```&#10;ან: `cd ElasticSearch.Jobs &amp;&amp; dotnet run`&#10;&#10;---&#10;&#10;## ✨ ეს ყველაფერია!&#10;&#10;არაფერი არ უნდა გააკეთოთ ხელით - ყველაფერი ავტომატურია!&#10;&#10;---&#10;&#10;##  ტესტირება&#10;&#10;გახსენით: **http://localhost:5000**&#10;&#10;Swagger-ში სცადეთ:&#10;```&#10;GET /api/products/search                    # ყველა პროდუქტი&#10;GET /api/products/search?query=laptop       # ძებნა&#10;GET /api/products/search?category=Laptops   # ფილტრი&#10;```&#10;&#10;---&#10;&#10;##  რა მონაცემები ჩაიტვირთება?&#10;&#10;**15 პროდუქტი** ქართული აღწერილობებით:&#10;-  Laptops: MacBook Pro, Dell XPS, Lenovo ThinkPad&#10;-  Smartphones: iPhone 15, Samsung S24, Google Pixel&#10;-  Audio: Sony WH-1000XM5&#10;-  Components: RAM, SSD, GPU&#10;- და სხვა...&#10;&#10;---&#10;&#10;##  სინქრონიზაცია&#10;&#10;| ტიპი | სიხშირე |&#10;|------|---------|&#10;| Initial Sync | Jobs დასტარტვისას |&#10;| Incremental | ყოველ 5 წუთში |&#10;| Daily Full | 02:00 საათზე |&#10;| Weekly Full | კვირას 03:00 |&#10;&#10;---&#10;&#10;##  Links&#10;&#10;- Swagger: http://localhost:5000&#10;- Elasticsearch: http://localhost:9200&#10;- Kibana: http://localhost:5601&#10;&#10;---&#10;&#10;##  გაჩერება&#10;&#10;```cmd&#10;stop-all.bat&#10;```&#10;ან: `docker-compose down` + Ctrl+C terminal-ებში&#10;&#10;---&#10;&#10;##  დეტალური დოკუმენტაცია&#10;&#10;- [QUICK_START_3_STEPS.md](QUICK_START_3_STEPS.md) - ნაბიჯ-ნაბიჯ გაიდი&#10;- [AUTO_SYNC_GUIDE.md](AUTO_SYNC_GUIDE.md) - სინქრონიზაციის დეტალები&#10;- [README_UPDATED.md](README_UPDATED.md) - სრული დოკუმენტაცია&#10;- [ELASTICSEARCH_DEEP_DIVE.md](ELASTICSEARCH_DEEP_DIVE.md) - Elasticsearch გაკვეთილები&#10;&#10;---&#10;&#10;##  რას ასწავლის პროექტი&#10;&#10;- ✅ Elasticsearch integration (.NET)&#10;- ✅ Full-text search &amp; aggregations&#10;- ✅ Background jobs (Hangfire)&#10;- ✅ SQL Server → Elasticsearch sync&#10;- ✅ REST API (ASP.NET Core)&#10;- ✅ Clean Architecture&#10;- ✅ Docker &amp; docker-compose&#10;&#10;---&#10;&#10;**იმდენად მარტივია! **&#10;&#10;" />
              <option name="updatedContent" value="#  Elasticsearch Demo - ავტომატური სინქრონიზაცია&#10;&#10;## ⚠️ პირობები&#10;&#10;**აუცილებლად უნდა იყოს გაშვებული:**&#10;- ✅ SQL Server (LocalDB/Express/Full)&#10;- ✅ Docker Desktop&#10;&#10;შემოწმება:&#10;```cmd&#10;sqlcmd -S localhost -E -Q &quot;SELECT 1&quot;&#10;docker info&#10;```&#10;&#10;---&#10;&#10;## ⚡ რას აკეთებს?&#10;&#10;**დასტარტვისას ავტომატურად:**&#10;- ✅ ქმნის SQL Server მონაცემთა ბაზას (`ElasticsearchDemo`)&#10;- ✅ ქმნის `Products` ცხრილს&#10;- ✅ ატვირთავს 15 სატესტო პროდუქტს (თუ ცხრილი ცარიელია)&#10;- ✅ სინქრონიზებას უკეთებს Elasticsearch-თან&#10;- ✅ აგრძელებს real-time სინქრონიზაციას ყოველ 5 წუთში&#10;&#10;---&#10;&#10;##  სწრაფი დასტარტვა&#10;&#10;### 1️⃣ Elasticsearch + Kibana&#10;```cmd&#10;start-infrastructure.bat&#10;```&#10;ან: `docker-compose up -d`&#10;&#10;⏱️ დაელოდეთ 30 წამს&#10;&#10;### 2️⃣ API (ახალ terminal)&#10;```cmd&#10;start-api.bat&#10;```&#10;ან: `cd ElasticSearch.Api &amp;&amp; dotnet run`&#10;&#10;→ **http://localhost:5000** (Swagger)&#10;&#10;### 3️⃣ Jobs (ახალ terminal)&#10;```cmd&#10;start-jobs.bat&#10;```&#10;ან: `cd ElasticSearch.Jobs &amp;&amp; dotnet run`&#10;&#10;---&#10;&#10;## ✨ ეს ყველაფერია!&#10;&#10;არაფერი არ უნდა გააკეთოთ ხელით - ყველაფერი ავტომატურია!&#10;&#10;---&#10;&#10;##  ტესტირება&#10;&#10;გახსენით: **http://localhost:5000**&#10;&#10;Swagger-ში სცადეთ:&#10;```&#10;GET /api/products/search                    # ყველა პროდუქტი&#10;GET /api/products/search?query=laptop       # ძებნა&#10;GET /api/products/search?category=Laptops   # ფილტრი&#10;```&#10;&#10;---&#10;&#10;##  რა მონაცემები ჩაიტვირთება?&#10;&#10;**15 პროდუქტი** ქართული აღწერილობებით:&#10;-  Laptops: MacBook Pro, Dell XPS, Lenovo ThinkPad&#10;-  Smartphones: iPhone 15, Samsung S24, Google Pixel&#10;-  Audio: Sony WH-1000XM5&#10;-  Components: RAM, SSD, GPU&#10;- და სხვა...&#10;&#10;---&#10;&#10;##  სინქრონიზაცია&#10;&#10;| ტიპი | სიხშირე |&#10;|------|---------|&#10;| Initial Sync | Jobs დასტარტვისას |&#10;| Incremental | ყოველ 5 წუთში |&#10;| Daily Full | 02:00 საათზე |&#10;| Weekly Full | კვირას 03:00 |&#10;&#10;---&#10;&#10;##  Links&#10;&#10;- Swagger: http://localhost:5000&#10;- Elasticsearch: http://localhost:9200&#10;- Kibana: http://localhost:5601&#10;&#10;---&#10;&#10;##  გაჩერება&#10;&#10;```cmd&#10;stop-all.bat&#10;```&#10;ან: `docker-compose down` + Ctrl+C terminal-ებში&#10;&#10;---&#10;&#10;##  დეტალური დოკუმენტაცია&#10;&#10;- [QUICK_START_3_STEPS.md](QUICK_START_3_STEPS.md) - ნაბიჯ-ნაბიჯ გაიდი&#10;- [AUTO_SYNC_GUIDE.md](AUTO_SYNC_GUIDE.md) - სინქრონიზაციის დეტალები&#10;- [README_UPDATED.md](README_UPDATED.md) - სრული დოკუმენტაცია&#10;- [ELASTICSEARCH_DEEP_DIVE.md](ELASTICSEARCH_DEEP_DIVE.md) - Elasticsearch გაკვეთილები&#10;&#10;---&#10;&#10;##  რას ასწავლის პროექტი&#10;&#10;- ✅ Elasticsearch integration (.NET)&#10;- ✅ Full-text search &amp; aggregations&#10;- ✅ Background jobs (Hangfire)&#10;- ✅ SQL Server → Elasticsearch sync&#10;- ✅ REST API (ASP.NET Core)&#10;- ✅ Clean Architecture&#10;- ✅ Docker &amp; docker-compose&#10;&#10;---&#10;&#10;**იმდენად მარტივია! **&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/check-prerequisites.bat">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/check-prerequisites.bat" />
              <option name="updatedContent" value="@echo off&#10;echo ╔══════════════════════════════════════════════════════════════╗&#10;echo ║     სისტემის მოთხოვნების შემოწმება                           ║&#10;echo ╚══════════════════════════════════════════════════════════════╝&#10;echo.&#10;&#10;set ALL_OK=1&#10;&#10;REM Check SQL Server&#10;echo  SQL Server-ის შემოწმება...&#10;sqlcmd -S localhost -E -Q &quot;SELECT 1&quot; &gt; nul 2&gt;&amp;1&#10;if errorlevel 1 (&#10;    echo ❌ SQL Server არ არის ხელმისაწვდომი&#10;    echo    გთხოვთ გაუშვათ SQL Server Service&#10;    set ALL_OK=0&#10;) else (&#10;    echo ✅ SQL Server გაშვებულია&#10;)&#10;echo.&#10;&#10;REM Check Docker&#10;echo  Docker-ის შემოწმება...&#10;docker info &gt; nul 2&gt;&amp;1&#10;if errorlevel 1 (&#10;    echo ❌ Docker არ არის გაშვებული&#10;    echo    გთხოვთ გაუშვათ Docker Desktop&#10;    set ALL_OK=0&#10;) else (&#10;    echo ✅ Docker გაშვებულია&#10;)&#10;echo.&#10;&#10;REM Check .NET SDK&#10;echo  .NET SDK-ის შემოწმება...&#10;dotnet --version &gt; nul 2&gt;&amp;1&#10;if errorlevel 1 (&#10;    echo ❌ .NET SDK არ არის დაინსტალირებული&#10;    set ALL_OK=0&#10;) else (&#10;    echo ✅ .NET SDK დაინსტალირებულია&#10;    for /f &quot;delims=&quot; %%i in ('dotnet --version') do echo    Version: %%i&#10;)&#10;echo.&#10;&#10;REM Summary&#10;echo ╔══════════════════════════════════════════════════════════════╗&#10;if %ALL_OK%==1 (&#10;    echo ║     ✅ ყველაფერი მზადაა!                                     ║&#10;    echo ╚══════════════════════════════════════════════════════════════╝&#10;    echo.&#10;    echo შეგიძლიათ დაიწყოთ აპლიკაცია:&#10;    echo   1. start-infrastructure.bat&#10;    echo   2. start-api.bat&#10;    echo   3. start-jobs.bat&#10;) else (&#10;    echo ║     ⚠️  გთხოვთ გაასწოროთ პრობლემები                          ║&#10;    echo ╚══════════════════════════════════════════════════════════════╝&#10;)&#10;echo.&#10;pause&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docker-compose.yml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docker-compose.yml" />
              <option name="originalContent" value="&#10;services:&#10;  # SQL Server Service&#10;  sqlserver:&#10;    image: mcr.microsoft.com/mssql/server:2022-latest&#10;    container_name: sqlserver&#10;    environment:&#10;      - ACCEPT_EULA=Y&#10;      - SA_PASSWORD=${SA_PASSWORD:-Password1234}&#10;      - MSSQL_PID=Developer&#10;    ports:&#10;      - &quot;1433:1433&quot;&#10;    volumes:&#10;      - sqlserver-data:/var/opt/mssql&#10;    networks:&#10;      - elastic-network&#10;    healthcheck:&#10;      test: [&quot;CMD-SHELL&quot;, &quot;/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P $$SA_PASSWORD -Q 'SELECT 1' || exit 1&quot;]&#10;      interval: 10s&#10;      timeout: 5s&#10;      retries: 30&#10;&#10;  # Elasticsearch Service&#10;  elasticsearch:&#10;    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0&#10;    container_name: elasticsearch&#10;    environment:&#10;      - discovery.type=single-node&#10;      - xpack.security.enabled=false&#10;      - xpack.security.http.ssl.enabled=false&#10;      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;&#10;      - bootstrap.memory_lock=true&#10;    ulimits:&#10;      memlock:&#10;        soft: -1&#10;        hard: -1&#10;    volumes:&#10;      - elasticsearch-data:/usr/share/elasticsearch/data&#10;    ports:&#10;      - &quot;9200:9200&quot;&#10;      - &quot;9300:9300&quot;&#10;    networks:&#10;      - elastic-network&#10;    healthcheck:&#10;      test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:9200/_cluster/health || exit 1&quot;]&#10;      interval: 10s&#10;      timeout: 5s&#10;      retries: 30&#10;&#10;  # Kibana Service&#10;  kibana:&#10;    image: docker.elastic.co/kibana/kibana:8.11.0&#10;    container_name: kibana&#10;    environment:&#10;      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200&#10;      - ELASTICSEARCH_URL=http://elasticsearch:9200&#10;    ports:&#10;      - &quot;5601:5601&quot;&#10;    networks:&#10;      - elastic-network&#10;    depends_on:&#10;      elasticsearch:&#10;        condition: service_healthy&#10;    healthcheck:&#10;      test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:5601/api/status || exit 1&quot;]&#10;      interval: 10s&#10;      timeout: 5s&#10;      retries: 30&#10;&#10;  # ElasticSearch API Service&#10;  api:&#10;    build:&#10;      context: .&#10;      dockerfile: ElasticSearch.Api/Dockerfile&#10;    container_name: elasticsearch-api&#10;    environment:&#10;      - ASPNETCORE_ENVIRONMENT=${ASPNETCORE_ENVIRONMENT:-Development}&#10;      - ASPNETCORE_URLS=http://+:8080&#10;      - ConnectionStrings__SqlServer=Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=${SA_PASSWORD:-Password1234};TrustServerCertificate=True;&#10;      - Elasticsearch__Uri=${ELASTICSEARCH_URI:-http://elasticsearch:9200}&#10;    ports:&#10;      - &quot;${API_PORT:-5000}:8080&quot;&#10;    networks:&#10;      - elastic-network&#10;    depends_on:&#10;      elasticsearch:&#10;        condition: service_healthy&#10;      sqlserver:&#10;        condition: service_healthy&#10;    restart: unless-stopped&#10;&#10;  # Background Jobs Service&#10;  jobs:&#10;    build:&#10;      context: .&#10;      dockerfile: ElasticSearch.Jobs/Dockerfile&#10;    container_name: elasticsearch-jobs&#10;    environment:&#10;      - ConnectionStrings__SqlServer=Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=${SA_PASSWORD:-YourStrong@Password123};TrustServerCertificate=True;&#10;      - ConnectionStrings__Hangfire=Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=${SA_PASSWORD:-YourStrong@Password123};TrustServerCertificate=True;&#10;      - Elasticsearch__Uri=${ELASTICSEARCH_URI:-http://elasticsearch:9200}&#10;    networks:&#10;      - elastic-network&#10;    depends_on:&#10;      elasticsearch:&#10;        condition: service_healthy&#10;      sqlserver:&#10;        condition: service_healthy&#10;    restart: unless-stopped&#10;&#10;volumes:&#10;  elasticsearch-data:&#10;    driver: local&#10;  sqlserver-data:&#10;    driver: local&#10;&#10;networks:&#10;  elastic-network:&#10;    driver: bridge&#10;&#10;" />
              <option name="updatedContent" value="&#10;services:&#10;  # SQL Server Service&#10;  sqlserver:&#10;    image: mcr.microsoft.com/mssql/server:2022-latest&#10;    container_name: sqlserver&#10;    environment:&#10;      - ACCEPT_EULA=Y&#10;      - SA_PASSWORD=Password1234!&#10;      - MSSQL_PID=Developer&#10;    ports:&#10;      - &quot;1433:1433&quot;&#10;    volumes:&#10;      - sqlserver-data:/var/opt/mssql&#10;    networks:&#10;      - elastic-network&#10;    healthcheck:&#10;      test: [&quot;CMD-SHELL&quot;, &quot;/opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P 'Password1234!' -C -Q 'SELECT 1' || exit 1&quot;]&#10;      interval: 10s&#10;      timeout: 5s&#10;      retries: 30&#10;&#10;  # Elasticsearch Service&#10;  elasticsearch:&#10;    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0&#10;    container_name: elasticsearch&#10;    environment:&#10;      - discovery.type=single-node&#10;      - xpack.security.enabled=false&#10;      - xpack.security.http.ssl.enabled=false&#10;      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;&#10;      - bootstrap.memory_lock=true&#10;    ulimits:&#10;      memlock:&#10;        soft: -1&#10;        hard: -1&#10;    volumes:&#10;      - elasticsearch-data:/usr/share/elasticsearch/data&#10;    ports:&#10;      - &quot;9200:9200&quot;&#10;      - &quot;9300:9300&quot;&#10;    networks:&#10;      - elastic-network&#10;    healthcheck:&#10;      test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:9200/_cluster/health || exit 1&quot;]&#10;      interval: 10s&#10;      timeout: 5s&#10;      retries: 30&#10;&#10;  # Kibana Service&#10;  kibana:&#10;    image: docker.elastic.co/kibana/kibana:8.11.0&#10;    container_name: kibana&#10;    environment:&#10;      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200&#10;      - ELASTICSEARCH_URL=http://elasticsearch:9200&#10;    ports:&#10;      - &quot;5601:5601&quot;&#10;    networks:&#10;      - elastic-network&#10;    depends_on:&#10;      elasticsearch:&#10;        condition: service_healthy&#10;    healthcheck:&#10;      test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:5601/api/status || exit 1&quot;]&#10;      interval: 10s&#10;      timeout: 5s&#10;      retries: 30&#10;&#10;  # ElasticSearch API Service&#10;  api:&#10;    build:&#10;      context: .&#10;      dockerfile: ElasticSearch.Api/Dockerfile&#10;    container_name: elasticsearch-api&#10;    environment:&#10;      - ASPNETCORE_ENVIRONMENT=Production&#10;      - ASPNETCORE_URLS=http://+:8080&#10;      - ConnectionStrings__SqlServer=Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=Password1234!;TrustServerCertificate=True;&#10;      - Elasticsearch__Uri=http://elasticsearch:9200&#10;    ports:&#10;      - &quot;5000:8080&quot;&#10;    networks:&#10;      - elastic-network&#10;    depends_on:&#10;      elasticsearch:&#10;        condition: service_healthy&#10;      sqlserver:&#10;        condition: service_healthy&#10;    restart: unless-stopped&#10;&#10;  # Background Jobs Service&#10;  jobs:&#10;    build:&#10;      context: .&#10;      dockerfile: ElasticSearch.Jobs/Dockerfile&#10;    container_name: elasticsearch-jobs&#10;    environment:&#10;      - DOTNET_ENVIRONMENT=Production&#10;      - ConnectionStrings__SqlServer=Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=Password1234!;TrustServerCertificate=True;&#10;      - ConnectionStrings__Hangfire=Server=sqlserver,1433;Database=ElasticsearchDemo;User Id=sa;Password=Password1234!;TrustServerCertificate=True;&#10;      - Elasticsearch__Uri=http://elasticsearch:9200&#10;    networks:&#10;      - elastic-network&#10;    depends_on:&#10;      elasticsearch:&#10;        condition: service_healthy&#10;      sqlserver:&#10;        condition: service_healthy&#10;    restart: unless-stopped&#10;&#10;volumes:&#10;  elasticsearch-data:&#10;    driver: local&#10;  sqlserver-data:&#10;    driver: local&#10;&#10;networks:&#10;  elastic-network:&#10;    driver: bridge&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docker-init/01-create-admin-user.sql">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docker-init/01-create-admin-user.sql" />
              <option name="updatedContent" value="-- Wait for SQL Server to be ready&#10;WAITFOR DELAY '00:00:05';&#10;GO&#10;&#10;USE master;&#10;GO&#10;&#10;-- Create Login 'admin'&#10;IF NOT EXISTS (SELECT * FROM sys.server_principals WHERE name = 'admin')&#10;BEGIN&#10;    CREATE LOGIN [admin] WITH PASSWORD = 'Password1234';&#10;    PRINT 'Login [admin] created successfully';&#10;END&#10;ELSE&#10;BEGIN&#10;    PRINT 'Login [admin] already exists';&#10;END&#10;GO&#10;&#10;-- Create Database if not exists&#10;IF NOT EXISTS (SELECT * FROM sys.databases WHERE name = 'ElasticsearchDemo')&#10;BEGIN&#10;    CREATE DATABASE ElasticsearchDemo;&#10;    PRINT 'Database [ElasticsearchDemo] created successfully';&#10;END&#10;ELSE&#10;BEGIN&#10;    PRINT 'Database [ElasticsearchDemo] already exists';&#10;END&#10;GO&#10;&#10;-- Switch to the database&#10;USE ElasticsearchDemo;&#10;GO&#10;&#10;-- Create User 'admin'&#10;IF NOT EXISTS (SELECT * FROM sys.database_principals WHERE name = 'admin')&#10;BEGIN&#10;    CREATE USER [admin] FOR LOGIN [admin];&#10;    PRINT 'User [admin] created successfully';&#10;END&#10;ELSE&#10;BEGIN&#10;    PRINT 'User [admin] already exists';&#10;END&#10;GO&#10;&#10;-- Grant db_owner role to admin&#10;ALTER ROLE db_owner ADD MEMBER [admin];&#10;GO&#10;&#10;PRINT 'Setup completed: admin user with Password1234';&#10;GO&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docker-init/entrypoint.sh">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docker-init/entrypoint.sh" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="#!/bin/bash&#10;set -e&#10;&#10;echo &quot;Starting SQL Server...&quot;&#10;&#10;# Start SQL Server in background&#10;/opt/mssql/bin/sqlservr &amp;&#10;&#10;# Wait for SQL Server to be ready&#10;echo &quot;Waiting for SQL Server to start...&quot;&#10;sleep 30&#10;&#10;# Run initialization scripts&#10;if [ -d &quot;/docker-entrypoint-initdb.d&quot; ]; then&#10;    echo &quot;Running SQL initialization scripts...&quot;&#10;    for f in /docker-entrypoint-initdb.d/*.sql; do&#10;        if [ -f &quot;$f&quot; ]; then&#10;            echo &quot;Executing $f...&quot;&#10;            /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P &quot;$SA_PASSWORD&quot; -i &quot;$f&quot;&#10;            echo &quot;$f executed successfully&quot;&#10;        fi&#10;    done&#10;    echo &quot;All initialization scripts completed&quot;&#10;fi&#10;&#10;# Keep container running&#10;wait&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/start-infrastructure.bat">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/start-infrastructure.bat" />
              <option name="originalContent" value="@echo off&#10;echo ╔══════════════════════════════════════════════════════════════╗&#10;echo ║     ELASTICSEARCH DEMO - ᲡᲬᲠᲐᲤᲘ ᲓᲐᲡᲢᲐᲠᲢᲕᲐ                   ║&#10;echo ╚══════════════════════════════════════════════════════════════╝&#10;echo.&#10;&#10;REM Check if Docker is running&#10;docker info &gt; nul 2&gt;&amp;1&#10;if errorlevel 1 (&#10;    echo ❌ Docker არ არის გაშვებული!&#10;    echo გთხოვთ დაიწყოთ Docker Desktop და სცადოთ თავიდან&#10;    pause&#10;    exit /b 1&#10;)&#10;&#10;echo ✅ Docker გაშვებულია&#10;echo.&#10;&#10;REM Start Elasticsearch and Kibana&#10;echo  დაწყება: Elasticsearch და Kibana...&#10;docker-compose up -d&#10;&#10;echo.&#10;echo ⏳ მოლოდინი Elasticsearch-ის ჩატვირთვისთვის (30 წამი)...&#10;timeout /t 30 /nobreak &gt; nul&#10;&#10;echo.&#10;echo ╔══════════════════════════════════════════════════════════════╗&#10;echo ║     სისტემა მზად არის!                                       ║&#10;echo ╚══════════════════════════════════════════════════════════════╝&#10;echo.&#10;echo  Elasticsearch: http://localhost:9200&#10;echo  Kibana:        http://localhost:5601&#10;echo.&#10;echo შემდეგი ნაბიჯები:&#10;echo.&#10;echo 1. გახსენით ახალი terminal და გაუშვით:&#10;echo    dotnet run --project ElasticSearch.Api&#10;echo.&#10;echo 2. გახსენით კიდევ ერთი terminal და გაუშვით:&#10;echo    dotnet run --project ElasticSearch.Jobs&#10;echo.&#10;pause&#10;&#10;" />
              <option name="updatedContent" value="@echo off&#10;echo ╔══════════════════════════════════════════════════════════════╗&#10;echo ║     ELASTICSEARCH DEMO - ᲡᲬᲠᲐᲤᲘ ᲓᲐᲡᲢᲐᲠᲢᲕᲐ                   ║&#10;echo ╚══════════════════════════════════════════════════════════════╝&#10;echo.&#10;&#10;REM Check if SQL Server is running&#10;echo  შემოწმება: SQL Server...&#10;sqlcmd -S localhost -E -Q &quot;SELECT 1&quot; &gt; nul 2&gt;&amp;1&#10;if errorlevel 1 (&#10;    echo ❌ SQL Server არ არის გაშვებული ან არ არის ხელმისაწვდომი!&#10;    echo.&#10;    echo გთხოვთ დარწმუნდით რომ SQL Server გაშვებულია:&#10;    echo - SQL Server Management Studio-დან შეამოწმეთ&#10;    echo - ან დაიწყეთ SQL Server Service&#10;    echo.&#10;    pause&#10;    exit /b 1&#10;)&#10;echo ✅ SQL Server გაშვებულია&#10;echo.&#10;&#10;REM Check if Docker is running&#10;echo  შემოწმება: Docker...&#10;docker info &gt; nul 2&gt;&amp;1&#10;if errorlevel 1 (&#10;    echo ❌ Docker არ არის გაშვებული!&#10;    echo გთხოვთ დაიწყოთ Docker Desktop და სცადოთ თავიდან&#10;    pause&#10;    exit /b 1&#10;)&#10;&#10;echo ✅ Docker გაშვებულია&#10;echo.&#10;&#10;REM Start Elasticsearch and Kibana&#10;echo  დაწყება: Elasticsearch და Kibana...&#10;docker-compose up -d&#10;&#10;echo.&#10;echo ⏳ მოლოდინი Elasticsearch-ის ჩატვირთვისთვის (30 წამი)...&#10;timeout /t 30 /nobreak &gt; nul&#10;&#10;echo.&#10;echo ╔══════════════════════════════════════════════════════════════╗&#10;echo ║     სისტემა მზად არის!                                       ║&#10;echo ╚══════════════════════════════════════════════════════════════╝&#10;echo.&#10;echo  Elasticsearch: http://localhost:9200&#10;echo  Kibana:        http://localhost:5601&#10;echo.&#10;echo შემდეგი ნაბიჯები:&#10;echo.&#10;echo 1. გახსენით ახალი terminal და გაუშვით:&#10;echo    dotnet run --project ElasticSearch.Api&#10;echo.&#10;echo 2. გახსენით კიდევ ერთი terminal და გაუშვით:&#10;echo    dotnet run --project ElasticSearch.Jobs&#10;echo.&#10;pause&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/start-local.bat">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/start-local.bat" />
              <option name="originalContent" value="@echo off&#10;echo ========================================&#10;echo   Start Infrastructure Only&#10;echo ========================================&#10;echo.&#10;echo Starting Elasticsearch and Kibana...&#10;echo SQL Server: Use LocalDB on Windows&#10;echo API and Jobs: Run with 'dotnet run'&#10;echo.&#10;&#10;docker-compose up -d elasticsearch kibana&#10;&#10;echo.&#10;echo ========================================&#10;echo   Infrastructure Started!&#10;echo ========================================&#10;echo.&#10;echo Elasticsearch: http://localhost:9200&#10;echo Kibana:        http://localhost:5601&#10;echo.&#10;echo Next Steps:&#10;echo   1. cd ElasticSearch.Jobs&#10;echo   2. dotnet run&#10;echo.&#10;echo   (In another terminal)&#10;echo   3. cd ElasticSearch.Api  &#10;echo   4. dotnet run&#10;echo.&#10;pause&#10;&#10;" />
              <option name="updatedContent" value="@echo off&#10;echo ========================================&#10;echo   Start Infrastructure (Docker)&#10;echo ========================================&#10;echo.&#10;echo Starting Elasticsearch and Kibana in Docker...&#10;echo.&#10;echo Note: API and Jobs will run locally with LocalDB&#10;echo       (Docker containers cannot access LocalDB)&#10;echo.&#10;&#10;docker-compose up -d&#10;&#10;echo.&#10;echo ========================================&#10;echo   Infrastructure Started!&#10;echo ========================================&#10;echo.&#10;echo Services:&#10;echo   - Elasticsearch: http://localhost:9200&#10;echo   - Kibana:        http://localhost:5601&#10;echo.&#10;echo Database:&#10;echo   - LocalDB:       (localdb)\MSSQLLocalDB&#10;echo.&#10;echo ========================================&#10;echo   Next Steps:&#10;echo ========================================&#10;echo.&#10;echo 1. Open NEW terminal:&#10;echo    cd ElasticSearch.Jobs&#10;echo    dotnet run&#10;echo.&#10;echo 2. Open ANOTHER terminal:&#10;echo    cd ElasticSearch.Api&#10;echo    dotnet run&#10;echo.&#10;echo 3. Access:&#10;echo    API:    http://localhost:5000&#10;echo    Kibana: http://localhost:5601&#10;echo.&#10;pause&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>